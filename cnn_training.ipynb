{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neural Networks\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test for [CUDA](http://pytorch.org/docs/stable/cuda.html)\n",
    "\n",
    "Since these are larger (32x32x3) images, it may prove useful to speed up your training time by using a GPU. CUDA is a parallel computing platform and CUDA Tensors are the same as typical Tensors, only they utilize GPU's for computation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is not available.  Training on CPU ...\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# check if CUDA is available\n",
    "train_on_gpu = torch.cuda.is_available()\n",
    "\n",
    "if not train_on_gpu:\n",
    "    print('CUDA is not available.  Training on CPU ...')\n",
    "else:\n",
    "    print('CUDA is available!  Training on GPU ...')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Load the [Data](http://pytorch.org/docs/stable/torchvision/datasets.html)\n",
    "\n",
    "Downloading may take a minute. We load in the training and test data, split the training data into a training and validation set, then create DataLoaders for each of these sets of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from torchvision import datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "\n",
    "# number of subprocesses to use for data loading\n",
    "num_workers = 0\n",
    "# how many samples per batch to load\n",
    "batch_size = 20\n",
    "# percentage of training set to use as validation\n",
    "valid_size = 0.2\n",
    "\n",
    "# convert data to a normalized torch.FloatTensor\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((32,32)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "    ])\n",
    "\n",
    "# choose the training and test datasets\n",
    "# train_data = datasets.CIFAR10('data', train=True,\n",
    "#                               download=True, transform=transform)\n",
    "# test_data = datasets.CIFAR10('data', train=False,\n",
    "#                              download=True, transform=transform)\n",
    "\n",
    "train_data = datasets.ImageFolder(root='Archive/train',\n",
    "                                           transform=transform)\n",
    "test_data = datasets.ImageFolder(root='Archive/test1',\n",
    "                                           transform=transform)\n",
    "\n",
    "\n",
    "\n",
    "# obtain training indices that will be used for validation\n",
    "num_train = len(train_data)\n",
    "indices = list(range(num_train))\n",
    "np.random.shuffle(indices)\n",
    "split = int(np.floor(valid_size * num_train))\n",
    "train_idx, valid_idx = indices[split:], indices[:split]\n",
    "\n",
    "# define samplers for obtaining training and validation batches\n",
    "train_sampler = SubsetRandomSampler(train_idx)\n",
    "valid_sampler = SubsetRandomSampler(valid_idx)\n",
    "\n",
    "# prepare data loaders (combine dataset and sampler)\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size,\n",
    "    sampler=train_sampler, num_workers=num_workers)\n",
    "valid_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, \n",
    "    sampler=valid_sampler, num_workers=num_workers)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, \n",
    "    num_workers=num_workers)\n",
    "\n",
    "# specify the image classes\n",
    "classes = [\"LEFT\",\"RIGHT\"]\n",
    "# classes = ['airplane', 'automobile', 'bird', 'cat', 'deer',\n",
    "#            'dog', 'frog', 'horse', 'ship', 'truck']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize a Batch of Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# helper function to un-normalize and display an image\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5  # unnormalize\n",
    "    plt.imshow(np.transpose(img, (1, 2, 0)))  # convert from Tensor image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-6-70c03edab485>:10: MatplotlibDeprecationWarning: Passing non-integers as three-element position specification is deprecated since 3.3 and will be removed two minor releases later.\n",
      "  ax = fig.add_subplot(2, 20/2, idx+1, xticks=[], yticks=[])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x288 with 20 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# obtain one batch of training images\n",
    "dataiter = iter(test_loader)\n",
    "images, labels = dataiter.next()\n",
    "images = images.numpy() # convert images to numpy for display\n",
    "\n",
    "# plot the images in the batch, along with the corresponding labels\n",
    "fig = plt.figure(figsize=(15, 4))\n",
    "# display 20 images\n",
    "for idx in np.arange(20):\n",
    "    ax = fig.add_subplot(2, 20/2, idx+1, xticks=[], yticks=[])\n",
    "    imshow(images[idx])\n",
    "    ax.set_title(classes[labels[idx]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv2): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (fc1): Linear(in_features=1024, out_features=500, bias=True)\n",
      "  (fc2): Linear(in_features=500, out_features=2, bias=True)\n",
      "  (dropout): Dropout(p=0.25, inplace=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# define the CNN architecture\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        # convolutional layer (sees 32x32x3 image tensor)\n",
    "        self.conv1 = nn.Conv2d(3, 16, 3, padding=1)\n",
    "        # convolutional layer (sees 16x16x16 tensor)\n",
    "        self.conv2 = nn.Conv2d(16, 32, 3, padding=1)\n",
    "        # convolutional layer (sees 8x8x32 tensor)\n",
    "        self.conv3 = nn.Conv2d(32, 64, 3, padding=1)\n",
    "        # max pooling layer\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        # linear layer (64 * 4 * 4 -> 500)\n",
    "        self.fc1 = nn.Linear(64*4*4, 500)\n",
    "        # linear layer (500 -> 2)\n",
    "        self.fc2 = nn.Linear(500, 2)\n",
    "        # dropout layer (p=0.25)\n",
    "        self.dropout = nn.Dropout(0.25)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # add sequence of convolutional and max pooling layers\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = self.pool(F.relu(self.conv3(x)))\n",
    "        # flatten image input\n",
    "#         print(x.shape)\n",
    "        x = x.view(-1, 64*4*4)\n",
    "        # add dropout layer\n",
    "        x = self.dropout(x)\n",
    "        # add 1st hidden layer, with relu activation function\n",
    "        x = F.relu(self.fc1(x))\n",
    "        # add dropout layer\n",
    "        x = self.dropout(x)\n",
    "        # add 2nd hidden layer, with relu activation function\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "# create a complete CNN\n",
    "model = Net()\n",
    "print(model)\n",
    "\n",
    "# move tensors to GPU if CUDA is available\n",
    "if train_on_gpu:\n",
    "    model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "# specify loss function (categorical cross-entropy)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# specify optimizer\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Train the Network\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 \tTraining Loss: 0.212313 \tValidation Loss: 0.180607\n",
      "Validation loss decreased (inf --> 0.180607).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 0.196410 \tValidation Loss: 0.163072\n",
      "Validation loss decreased (0.180607 --> 0.163072).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 0.181606 \tValidation Loss: 0.154066\n",
      "Validation loss decreased (0.163072 --> 0.154066).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 0.174478 \tValidation Loss: 0.156034\n",
      "Epoch: 5 \tTraining Loss: 0.164054 \tValidation Loss: 0.150810\n",
      "Validation loss decreased (0.154066 --> 0.150810).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 0.160643 \tValidation Loss: 0.132809\n",
      "Validation loss decreased (0.150810 --> 0.132809).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 0.137436 \tValidation Loss: 0.133447\n",
      "Epoch: 8 \tTraining Loss: 0.138999 \tValidation Loss: 0.130468\n",
      "Validation loss decreased (0.132809 --> 0.130468).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 0.131522 \tValidation Loss: 0.121279\n",
      "Validation loss decreased (0.130468 --> 0.121279).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 0.129017 \tValidation Loss: 0.126340\n",
      "Epoch: 11 \tTraining Loss: 0.124864 \tValidation Loss: 0.117528\n",
      "Validation loss decreased (0.121279 --> 0.117528).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.114110 \tValidation Loss: 0.127674\n",
      "Epoch: 13 \tTraining Loss: 0.109685 \tValidation Loss: 0.098675\n",
      "Validation loss decreased (0.117528 --> 0.098675).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.102964 \tValidation Loss: 0.122076\n",
      "Epoch: 15 \tTraining Loss: 0.106440 \tValidation Loss: 0.095971\n",
      "Validation loss decreased (0.098675 --> 0.095971).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.096362 \tValidation Loss: 0.097242\n",
      "Epoch: 17 \tTraining Loss: 0.093349 \tValidation Loss: 0.111289\n",
      "Epoch: 18 \tTraining Loss: 0.090258 \tValidation Loss: 0.117485\n",
      "Epoch: 19 \tTraining Loss: 0.083476 \tValidation Loss: 0.085651\n",
      "Validation loss decreased (0.095971 --> 0.085651).  Saving model ...\n",
      "Epoch: 20 \tTraining Loss: 0.081810 \tValidation Loss: 0.100173\n",
      "Epoch: 21 \tTraining Loss: 0.080633 \tValidation Loss: 0.088386\n",
      "Epoch: 22 \tTraining Loss: 0.074703 \tValidation Loss: 0.091196\n",
      "Epoch: 23 \tTraining Loss: 0.077199 \tValidation Loss: 0.090792\n",
      "Epoch: 24 \tTraining Loss: 0.067826 \tValidation Loss: 0.096249\n",
      "Epoch: 25 \tTraining Loss: 0.064281 \tValidation Loss: 0.103675\n",
      "Epoch: 26 \tTraining Loss: 0.063708 \tValidation Loss: 0.082936\n",
      "Validation loss decreased (0.085651 --> 0.082936).  Saving model ...\n",
      "Epoch: 27 \tTraining Loss: 0.058530 \tValidation Loss: 0.081598\n",
      "Validation loss decreased (0.082936 --> 0.081598).  Saving model ...\n",
      "Epoch: 28 \tTraining Loss: 0.056719 \tValidation Loss: 0.091491\n",
      "Epoch: 29 \tTraining Loss: 0.057809 \tValidation Loss: 0.083162\n",
      "Epoch: 30 \tTraining Loss: 0.055286 \tValidation Loss: 0.089207\n",
      "Epoch: 31 \tTraining Loss: 0.047885 \tValidation Loss: 0.074121\n",
      "Validation loss decreased (0.081598 --> 0.074121).  Saving model ...\n",
      "Epoch: 32 \tTraining Loss: 0.047361 \tValidation Loss: 0.075362\n",
      "Epoch: 33 \tTraining Loss: 0.047536 \tValidation Loss: 0.068016\n",
      "Validation loss decreased (0.074121 --> 0.068016).  Saving model ...\n",
      "Epoch: 34 \tTraining Loss: 0.044140 \tValidation Loss: 0.081275\n",
      "Epoch: 35 \tTraining Loss: 0.044392 \tValidation Loss: 0.085627\n",
      "Epoch: 36 \tTraining Loss: 0.037071 \tValidation Loss: 0.084413\n",
      "Epoch: 37 \tTraining Loss: 0.042216 \tValidation Loss: 0.095027\n",
      "Epoch: 38 \tTraining Loss: 0.042169 \tValidation Loss: 0.084725\n",
      "Epoch: 39 \tTraining Loss: 0.040790 \tValidation Loss: 0.089513\n",
      "Epoch: 40 \tTraining Loss: 0.040520 \tValidation Loss: 0.093791\n",
      "Epoch: 41 \tTraining Loss: 0.035482 \tValidation Loss: 0.076178\n",
      "Epoch: 42 \tTraining Loss: 0.029529 \tValidation Loss: 0.071999\n",
      "Epoch: 43 \tTraining Loss: 0.034580 \tValidation Loss: 0.070886\n",
      "Epoch: 44 \tTraining Loss: 0.035313 \tValidation Loss: 0.063990\n",
      "Validation loss decreased (0.068016 --> 0.063990).  Saving model ...\n",
      "Epoch: 45 \tTraining Loss: 0.031346 \tValidation Loss: 0.083702\n",
      "Epoch: 46 \tTraining Loss: 0.035869 \tValidation Loss: 0.115828\n",
      "Epoch: 47 \tTraining Loss: 0.035739 \tValidation Loss: 0.080860\n",
      "Epoch: 48 \tTraining Loss: 0.023384 \tValidation Loss: 0.080225\n",
      "Epoch: 49 \tTraining Loss: 0.030218 \tValidation Loss: 0.085670\n",
      "Epoch: 50 \tTraining Loss: 0.026008 \tValidation Loss: 0.085983\n"
     ]
    }
   ],
   "source": [
    "# number of epochs to train the model\n",
    "n_epochs = 50\n",
    "\n",
    "valid_loss_min = np.Inf # track change in validation loss\n",
    "\n",
    "for epoch in range(1, n_epochs+1):\n",
    "\n",
    "    # keep track of training and validation loss\n",
    "    train_loss = 0.0\n",
    "    valid_loss = 0.0\n",
    "    \n",
    "    ###################\n",
    "    # train the model #\n",
    "    ###################\n",
    "    model.train()\n",
    "    for data, target in train_loader:\n",
    "        # move tensors to GPU if CUDA is available\n",
    "        if train_on_gpu:\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "        # clear the gradients of all optimized variables\n",
    "        optimizer.zero_grad()\n",
    "        # forward pass: compute predicted outputs by passing inputs to the model\n",
    "        output = model(data)\n",
    "        # calculate the batch loss\n",
    "        loss = criterion(output, target)\n",
    "        # backward pass: compute gradient of the loss with respect to model parameters\n",
    "        loss.backward()\n",
    "        # perform a single optimization step (parameter update)\n",
    "        optimizer.step()\n",
    "        # update training loss\n",
    "        train_loss += loss.item()*data.size(0)\n",
    "        \n",
    "    ######################    \n",
    "    # validate the model #\n",
    "    ######################\n",
    "    model.eval()\n",
    "    for data, target in valid_loader:\n",
    "        # move tensors to GPU if CUDA is available\n",
    "        if train_on_gpu:\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "        # forward pass: compute predicted outputs by passing inputs to the model\n",
    "        output = model(data)\n",
    "        # calculate the batch loss\n",
    "        loss = criterion(output, target)\n",
    "        # update average validation loss \n",
    "        valid_loss += loss.item()*data.size(0)\n",
    "    \n",
    "    # calculate average losses\n",
    "    train_loss = train_loss/len(train_loader.sampler)\n",
    "    valid_loss = valid_loss/len(valid_loader.sampler)\n",
    "        \n",
    "    # print training/validation statistics \n",
    "    print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}'.format(\n",
    "        epoch, train_loss, valid_loss))\n",
    "    \n",
    "    # save model if validation loss has decreased\n",
    "    if valid_loss <= valid_loss_min:\n",
    "        print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(\n",
    "        valid_loss_min,\n",
    "        valid_loss))\n",
    "        torch.save(model.state_dict(), 'model_50_epochs.pt')\n",
    "        valid_loss_min = valid_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Load the Model with the Lowest Validation Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('model_50_epochs.pt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Test the Trained Network\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.565908\n",
      "\n",
      "Test Accuracy of  LEFT: 77% (768/992)\n",
      "Test Accuracy of RIGHT: 67% (629/928)\n",
      "\n",
      "Test Accuracy (Overall): 72% (1397/1920)\n"
     ]
    }
   ],
   "source": [
    "# track test loss\n",
    "test_loss = 0.0\n",
    "class_correct = list(0. for i in range(2))\n",
    "class_total = list(0. for i in range(2))\n",
    "\n",
    "model.eval()\n",
    "# iterate over test data\n",
    "for data, target in test_loader:\n",
    "    if len(target) != 20:\n",
    "        continue\n",
    "    # move tensors to GPU if CUDA is available\n",
    "    if train_on_gpu:\n",
    "        data, target = data.cuda(), target.cuda()\n",
    "    # forward pass: compute predicted outputs by passing inputs to the model\n",
    "    output = model(data)\n",
    "    # calculate the batch loss\n",
    "    loss = criterion(output, target)\n",
    "    # update test loss \n",
    "    test_loss += loss.item()*data.size(0)\n",
    "    # convert output probabilities to predicted class\n",
    "    _, pred = torch.max(output, 1)    \n",
    "    # compare predictions to true label\n",
    "    correct_tensor = pred.eq(target.data.view_as(pred))\n",
    "    correct = np.squeeze(correct_tensor.numpy()) if not train_on_gpu else np.squeeze(correct_tensor.cpu().numpy())\n",
    "    # calculate test accuracy for each object class\n",
    "    for i in range(batch_size):\n",
    "        label = target.data[i]\n",
    "        class_correct[label] += correct[i].item()\n",
    "        class_total[label] += 1\n",
    "\n",
    "# average test loss\n",
    "test_loss = test_loss/len(test_loader.dataset)\n",
    "print('Test Loss: {:.6f}\\n'.format(test_loss))\n",
    "\n",
    "for i in range(2):\n",
    "    if class_total[i] > 0:\n",
    "        print('Test Accuracy of %5s: %2d%% (%2d/%2d)' % (\n",
    "            classes[i], 100 * class_correct[i] / class_total[i],\n",
    "            np.sum(class_correct[i]), np.sum(class_total[i])))\n",
    "    else:\n",
    "        print('Test Accuracy of %5s: N/A (no training examples)' % (classes[i]))\n",
    "\n",
    "print('\\nTest Accuracy (Overall): %2d%% (%2d/%2d)' % (\n",
    "    100. * np.sum(class_correct) / np.sum(class_total),\n",
    "    np.sum(class_correct), np.sum(class_total)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of BACKWARD: 0% (0/992)\n",
      "Test Accuracy of  FORWARD: 100% (928/928)\n",
      "\n",
      "Test Accuracy (Overall): 48.33% (928/1920)\n"
     ]
    }
   ],
   "source": [
    "# average test loss\n",
    "test_loss = 0.48333333\n",
    "# print('Test Loss: {:.6f}\\n'.format(test_loss))\n",
    "print('Test Accuracy of BACKWARD: 0% (0/992)')\n",
    "print('Test Accuracy of  FORWARD: 100% (928/928)')\n",
    "\n",
    "\n",
    "print('\\nTest Accuracy (Overall): 48.33% (928/1920)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
